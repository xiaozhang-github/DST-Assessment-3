{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Natural Language Processing work focusses on the Enron email data set which contains both spam and real emails for us to analyse. The research we wanted to perform was: *Analyse the Enron spam vs normal data set to create and visualise a topic model and understand the features of spam emails.* We did this by performing pre-processing on the data set, then creating a model and then analysing the resulting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a summary of the results we have found through our research into NLP on the Enron email set. We summarise with the classification report for each model and a data frame containing the perplexity and coherence scores for each optimal model created. More results and visualisations of models can be found within our own folders and should definitely be looked at to understand the analysis that took place since the complexity of that cannot be shown through the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifcation Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def classification_eval(y_true,y_pred):\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    C = confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    print('Classification report')\n",
    "    print(classification_report(y_true, y_pred, target_names = ['Normal', 'Spam'], digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the predictions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt's predictions\n",
    "Matt_actual = pickle.load(open('../Data/Actual.p','rb'))\n",
    "Matt_pred = pickle.load(open('../Data/Matt_pred.p','rb'))\n",
    "\n",
    "# Alex predictions\n",
    "Alex_actual = pickle.load(open('../Data/Alex_y_actual.p','rb')) \n",
    "Alex_pred = pickle.load(open('../Data/Alex_y_pred.p','rb'))\n",
    "\n",
    "# Xiao predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_eval(Matt_actual,Matt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_eval(Alex_actual,Alex_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_eval(Xiao_actual,Xiao_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity and Coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import our scores here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matt_values = pickle.load(open('../Data/Matt_opt_values.p','rb'))\n",
    "Matt_values = ['LDA Matt'] + Matt_values\n",
    "Matt_values.pop(2)\n",
    "\n",
    "Alex_values = pickle.load(open('../Data/Alex_optimal_values.p','rb'))\n",
    "Alex_values = ['LDA_td-idf Alex'] + Alex_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_df = pd.DataFrame(columns=['Model','Perplexity','c_v coherence'])\n",
    "co_df.loc[0] = Matt_values\n",
    "co_df.loc[1] = Alex_values\n",
    "#co_df.loc[2] = Xiao_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with removal of re/fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alex_rf_pred = pickle.load(open('../Data/y_pred_re.p','rb'))\n",
    "Alex_rf_actual = pickle.load(open('../Data/y_actual_re.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_eval(Alex_rf_actual,Alex_rf_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
